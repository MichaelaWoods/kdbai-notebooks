{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28f27f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key: ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = getpass('OpenAI API key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fcd4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyKX version: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import KDBAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de307b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF = \"/opt/kx/data/HNSW.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(PDF)\n",
    "pages = loader.load_and_split()\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12eea208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = pages[:1]  # Uncomment this when testing the pipeline to run on the first page only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d647e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyKX version: 1.6.0\n",
      "The model myIndex for algorithm 'hnsw' is now created.\n",
      "Setting the table: '.kdbai.table.data' as a global table within this process\n",
      "\n",
      "fitParams of the model:-\n",
      "dims          | 1536\n",
      "efConstruction| 8\n",
      "efSearch      | 8\n",
      "M             | 32\n",
      "errors        | 1b\n",
      "CPU times: user 422 ms, sys: 32.4 ms, total: 455 ms\n",
      "Wall time: 3.99 s\n",
      "Updating index with new vector data\n",
      "Updating in-memory table: '.kdbai.table.data' with new data\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import importlib\n",
    "from langchain.vectorstores import Chroma, Pinecone, kdbai\n",
    "importlib.reload(kdbai)\n",
    "\n",
    "TEMP = 0.0\n",
    "K = 10\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "options = dict(efConstruction=8, efSearch=8) # M is missing, and thus DEFAULT_M will be used\n",
    "vectordb = kdbai.KDBAI.from_documents(pages, \n",
    "                                      index_name=\"myIndex\", \n",
    "                                      embedding=embeddings, \n",
    "                                      persist_directory='tmp',\n",
    "                                      options=options)\n",
    "print('fitParams of the model:-')\n",
    "print(vectordb._model['fitParams'])\n",
    "\n",
    "# vectordb.persist()\n",
    "qabot = RetrievalQA.from_chain_type(chain_type='stuff',\n",
    "                                    llm=ChatOpenAI(model='gpt-3.5-turbo-16k', temperature=TEMP), \n",
    "                                    retriever=vectordb.as_retriever(search_kwargs=dict(k=K)),\n",
    "                                    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8432fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This research paper introduces a new approach for approximate nearest neighbor search called Hierarchical Navigable Small World (HNSW). The HNSW algorithm is a fully graph-based structure that aims to improve the performance and scalability of similarity search in large datasets. The algorithm utilizes proximity graphs and a heuristic for selecting neighbors to achieve logarithmic complexity scaling. The paper presents experimental results comparing HNSW with other state-of-the-art algorithms and demonstrates its superior performance in terms of query time and recall. The HNSW algorithm is also shown to be suitable for distributed implementation.\n",
      "CPU times: user 113 ms, sys: 3.63 ms, total: 117 ms\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Q = 'Summarize the content of this research paper'\n",
    "\n",
    "print(qabot(dict(query=Q))['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de375cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters used when building the index in Hierarchical NSW are:\n",
      "\n",
      "1. M: This parameter determines the maximum number of connections that an element can have in each layer of the index. It can be tuned to balance the trade-off between search performance and memory usage. Smaller values of M generally produce better results for lower recalls and/or lower dimensional data, while larger values of M are better for high recall and/or high dimensional data.\n",
      "\n",
      "2. efConstruction: This parameter controls the trade-off between index construction time and index quality. A higher value of efConstruction leads to longer construction time but potentially better index quality. It can be set to achieve a desired recall during the construction process.\n",
      "\n",
      "The parameters used when searching in Hierarchical NSW are:\n",
      "\n",
      "1. efSearch: This parameter controls the trade-off between search time and search quality. A higher value of efSearch leads to longer search time but potentially better search quality. It can be set to achieve a desired recall during the search process.\n",
      "\n",
      "To improve the output of the index, you can tune these parameters based on your specific requirements. For example, if you need faster search times, you can decrease the values of M and efSearch. On the other hand, if you need higher recall or better search quality, you can increase the values of M and efSearch. It is important to note that tuning these parameters may also affect the memory usage of the index, so you should consider the available resources when making adjustments.\n",
      "CPU times: user 103 ms, sys: 1.23 ms, total: 104 ms\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "Q = \"\"\"\n",
    "What are the parameters used when building the index or when searching ?\n",
    "Give me their names and how to tune those to improve the output.\n",
    "\"\"\"\n",
    "\n",
    "print(qabot(dict(query=Q))['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8d26dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The K parameter in the K-Nearest Neighbor Search (K-NNS) algorithm refers to the number of nearest neighbors that the algorithm should return. It determines how many elements from the dataset will be considered as potential matches for the query. \n",
      "\n",
      "The choice of the K parameter depends on the specific application and the desired trade-off between accuracy and computational efficiency. A smaller value of K will result in faster search times but may lead to a higher chance of missing some relevant neighbors. On the other hand, a larger value of K will provide more accurate results but may require more computational resources and time.\n",
      "\n",
      "It is important to note that the optimal value of K can vary depending on the dataset and the specific problem at hand. It is often determined through experimentation and performance evaluation.\n",
      "CPU times: user 102 ms, sys: 1.08 ms, total: 103 ms\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Q = 'What about the K parameter ?'\n",
    "\n",
    "print(qabot(dict(query=Q))['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71598fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
