{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3280b01a-d3b7-4ef6-9494-789d15bc48ec",
   "metadata": {},
   "source": [
    "# Semantic Search on PDF Documents with KDB.AI\n",
    "\n",
    "This example demonstrates how to use KDB.AI to run semantic search on unstructured text documents. \n",
    "\n",
    "Semantic search allows users to perform searches based on the meaning or similarity of the data rather than exact matches. It works by converting the query into a vector representation and then finding similar vectors in the database. This way, even if the query and the data in the database are not identical, the system can identify and retrieve the most relevant results based on their semantic meaning.\n",
    "\n",
    "## Aim\n",
    "In this tutorial, we'll walk you through the process of performing semantic search on documents, taking PDFs as example, using KDB.AI as the vector store. We will cover the following topics:\n",
    "\n",
    "- How to create vector embeddings using Sentence Transformer\n",
    "- How to store those embeddings in KDB.AI\n",
    "- How to search with a query using KDB.AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96697d51-a815-4ee9-acef-555afe28c2b6",
   "metadata": {},
   "source": [
    "## 1. Load and Split Document\n",
    "\n",
    "### Install Dependencies:\n",
    "\n",
    "We first need to install some libraries:\n",
    "- [PyDFF2](https://pypi.org/project/PyPDF2/) which is a useful library when handling PDFs in Python\n",
    "- [spaCy](https://spacy.io/) for advanced natural language processing which will help identify sentences in the PDF\n",
    "- [sentence-transformers](https://pypi.org/project/sentence-transformers/) we use the Sentence Transformers library to create embeddings for our collection of sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427beb75-cc0a-4a00-a64b-c7a80e197f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2 spacy sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6847ec-9cef-4648-82b9-b888620f7115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-06 08:32:35.247977: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 08:32:37.351187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2992812-4705-489d-974f-b7b44132343a",
   "metadata": {},
   "source": [
    "### Load and Split PDF into Sentences\n",
    "\n",
    "We leverage the power of PyPDF2 for PDF processing and spaCy for advanced natural language processing, the code below extracts content from each page of the PDF and processes it to identify sentences.\n",
    "\n",
    "The PDF we are using is [this research paper](https://arxiv.org/pdf/2308.05801.pdf) presenting information on the formation of Interstellar Objects in the Milky Way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbf9ede-6ed3-4171-bc77-2da673dcff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 08:32:49.631914: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 08:32:52.237129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def split_pdf_into_sentences(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "        # Extract text from each page and concatenate\n",
    "        full_text = \"\"\n",
    "        for page_number in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_number]\n",
    "            full_text += page.extract_text()\n",
    "\n",
    "        # Process the text using spaCy for sentence tokenization\n",
    "        doc = nlp(full_text)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "\n",
    "        return sentences\n",
    "\n",
    "\n",
    "# Define PDF path\n",
    "pdf_path = \"research_paper.pdf\"\n",
    "\n",
    "# Split the PDF into sentences\n",
    "pdf_sentences = split_pdf_into_sentences(pdf_path)\n",
    "len(pdf_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2558747e-4559-44b2-8ecb-88a583cc0ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Draft version August 14, 2023\\nTypeset using L ATEX default style in AASTeX631\\nThe Galactic Interstellar Object Population: A Framework for Prediction and Inference\\nMatthew J. Hopkins\\n ,1Chris Lintott\\n ,1Michele T. Bannister\\n ,'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea4179-8b26-4c40-89aa-ef6da11aafdf",
   "metadata": {},
   "source": [
    "## 2. Create Vector Embeddings \n",
    "\n",
    "Next, we use the Sentence Transformers library to create embeddings for our collection of sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1706a-6046-4dae-9b54-a59d4805f286",
   "metadata": {},
   "source": [
    "### Selecting a Sentence Transformer model\n",
    "\n",
    "There are 100+ of different types of Sentence Transformers models available - see [HuggingFace](https://huggingface.co/sentence-transformers) for the full list. The diversity among these primarily stems from variations in their training data. Selecting the ideal model for your needs involves matching the domain and task closely, while also considering the benefits of incorporating larger datasets to enhance scale. \n",
    "\n",
    "This tutorial will use the `all-MiniLM-L6-v2` pre-trained model, this embedding model can create sentence and document embeddings that can be used for a wide variety of tasks including semantic search which makes it a good choice for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823cc952-139a-49be-b5eb-802554aed708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4aaf7-69c5-4c56-b058-32ced66a62ee",
   "metadata": {},
   "source": [
    "### Generate embeddings\n",
    "\n",
    "We prepare embeddings by applying the sentence transformer model to our sentences to encode them. The we do some transformation to get this into DataFrame which is the format accepted by KDB.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d05b99a-121c-429e-864a-ee4bc5739224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectors</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0655135065317154, -0.09104187041521072, 0....</td>\n",
       "      <td>Draft version August 14, 2023\\nTypeset using L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.07847049832344055, -0.12151646614074707, 0...</td>\n",
       "      <td>2J. Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.07799108326435089, -0.08398671448230743, 0...</td>\n",
       "      <td>We define a novel framework: firstly to predic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.053385745733976364, -0.037147391587495804,...</td>\n",
       "      <td>We predict the spatial and compositional distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.06326977908611298, -0.01720457896590233, 0...</td>\n",
       "      <td>Selecting ISO water mass\\nfraction as an examp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>[-0.05012284219264984, -0.10081170499324799, -...</td>\n",
       "      <td>SDSS-IV is managed by the Astrophysical Resear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>[-0.07460089027881622, -0.06173836067318916, 0...</td>\n",
       "      <td>University of Tokyo, the Korean Participation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>[-0.07249360531568527, -0.05101025104522705, -...</td>\n",
       "      <td>Software: NumPy (Harris et al. 2020);</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>[-0.14471648633480072, -0.11599932610988617, 0...</td>\n",
       "      <td>SciPy (Virtanen et al. 2020); Astropy (Astropy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>[-0.06283451616764069, 0.021166836842894554, 0...</td>\n",
       "      <td>10.1029/2020JE006706\\nJewitt, D. 2003, Earth M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               vectors  \\\n",
       "0    [-0.0655135065317154, -0.09104187041521072, 0....   \n",
       "1    [-0.07847049832344055, -0.12151646614074707, 0...   \n",
       "2    [-0.07799108326435089, -0.08398671448230743, 0...   \n",
       "3    [-0.053385745733976364, -0.037147391587495804,...   \n",
       "4    [-0.06326977908611298, -0.01720457896590233, 0...   \n",
       "..                                                 ...   \n",
       "388  [-0.05012284219264984, -0.10081170499324799, -...   \n",
       "389  [-0.07460089027881622, -0.06173836067318916, 0...   \n",
       "390  [-0.07249360531568527, -0.05101025104522705, -...   \n",
       "391  [-0.14471648633480072, -0.11599932610988617, 0...   \n",
       "392  [-0.06283451616764069, 0.021166836842894554, 0...   \n",
       "\n",
       "                                             sentences  \n",
       "0    Draft version August 14, 2023\\nTypeset using L...  \n",
       "1    2J. Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Fo...  \n",
       "2    We define a novel framework: firstly to predic...  \n",
       "3    We predict the spatial and compositional distr...  \n",
       "4    Selecting ISO water mass\\nfraction as an examp...  \n",
       "..                                                 ...  \n",
       "388  SDSS-IV is managed by the Astrophysical Resear...  \n",
       "389  University of Tokyo, the Korean Participation ...  \n",
       "390              Software: NumPy (Harris et al. 2020);  \n",
       "391  SciPy (Virtanen et al. 2020); Astropy (Astropy...  \n",
       "392  10.1029/2020JE006706\\nJewitt, D. 2003, Earth M...  \n",
       "\n",
       "[393 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create embeddings\n",
    "embeddings_array = model.encode(np.array(pdf_sentences))\n",
    "embeddings_list = embeddings_array.tolist()\n",
    "embeddings_df = pd.DataFrame({\"vectors\": embeddings_list, \"sentences\": pdf_sentences})\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd119e3",
   "metadata": {},
   "source": [
    "It is important to note the dimension of our embeddings is 384. This will need to match the dimensions we set in the KDB.AI index in the next step. We can easily check this using `len` to count elements in our vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce60a36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_df[\"vectors\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70505eae-4138-4ba8-80e9-fc13c37d0b32",
   "metadata": {},
   "source": [
    "## 3. Store Embeddings in KDB.AI\n",
    "\n",
    "With the embeddings created, we need to store them in a vector database to enable efficient searching. KDB.AI is perfect for this task.\n",
    "\n",
    "### Connect to KDB.AI session\n",
    "\n",
    "To use KDB.AI, you will need two session details - a hostname and an API key. To get these you can sign up for free [here](#add_link).\n",
    "\n",
    "You can connect to a KDB.AI session using `kdbai.Session`. Replace the session details below with the ones you received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3a4932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import kdbai_client as kdbai\n",
    "\n",
    "# session = kdbai.Session(host='XXXX.kx.com', api_key=key)\n",
    "session = kdbai.Session(\n",
    "    host=\"localhost\", port=8082, protocol=\"http\"\n",
    ")  # remove for final release - should be replaced with line above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6525c",
   "metadata": {},
   "source": [
    "### Define schema\n",
    "\n",
    "The next step is to define a schema for our KDB.AI table where we will store our embeddings. Our table will have one column called `vectors`.\n",
    "\n",
    "At this point you will select the index and metric you want to use for searching.\n",
    "\n",
    "With KDB.AI we have the choice between HNSW (Hierarchical Navigable Small World) and Flat indexing methods. Generally, for semantic search of documents, the HNSW indexing method might be more suitable. Here's why:\n",
    "\n",
    "- **Search Speed and Approximation**: HNSW is designed for fast approximate nearest neighbour searches. It can efficiently handle high-dimensional data, which is common in natural language processing tasks involving text documents.\n",
    "- **Semantic Representation**: The Sentence Transformers library, used in this example, generates embeddings that capture semantic meaning. HNSW is well-suited for indexing such embeddings and performing semantic searches.\n",
    "- **Scalability**: HNSW is scalable and can handle large datasets effectively, making it suitable for applications with a vast number of documents.\n",
    "\n",
    "HNSW provides approximate search results, meaning that the nearest neighbors might not be exact matches but are close in terms of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af604df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_schema = {\n",
    "    \"columns\": [\n",
    "        {\"name\": \"sentences\", \"pytype\": \"str\"},\n",
    "        {\n",
    "            \"name\": \"vectors\",\n",
    "            \"vectorIndex\": {\"dims\": 384, \"metric\": \"L2\", \"type\": \"hnsw\"},\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cfe1e",
   "metadata": {},
   "source": [
    "### Create and save table\n",
    "\n",
    "Use `create_table` to create table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d190db-7c19-418e-9140-3dff04c9d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = session.create_table(\"pdf\", pdf_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466068bc",
   "metadata": {},
   "source": [
    "We can use `query` to see our table exists but is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74e7332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentences, vectors]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a9d0e-80b8-4e09-9101-d22667da551f",
   "metadata": {},
   "source": [
    "### Add embeddings to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83cc156c-8071-4784-8c3e-a049b61e8668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.insert(embeddings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a4ecd",
   "metadata": {},
   "source": [
    "Rerunning `query` we can now see data has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6ecb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Draft version August 14, 2023\\nTypeset using L...</td>\n",
       "      <td>[-0.0655135065317154, -0.09104187041521072, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2J. Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Fo...</td>\n",
       "      <td>[-0.07847049832344055, -0.12151646614074707, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We define a novel framework: firstly to predic...</td>\n",
       "      <td>[-0.07799108326435089, -0.08398671448230743, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We predict the spatial and compositional distr...</td>\n",
       "      <td>[-0.053385745733976364, -0.037147391587495804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selecting ISO water mass\\nfraction as an examp...</td>\n",
       "      <td>[-0.06326977908611298, -0.01720457896590233, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>SDSS-IV is managed by the Astrophysical Resear...</td>\n",
       "      <td>[-0.05012284219264984, -0.10081170499324799, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>University of Tokyo, the Korean Participation ...</td>\n",
       "      <td>[-0.07460089027881622, -0.06173836067318916, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Software: NumPy (Harris et al. 2020);</td>\n",
       "      <td>[-0.07249360531568527, -0.05101025104522705, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>SciPy (Virtanen et al. 2020); Astropy (Astropy...</td>\n",
       "      <td>[-0.14471648633480072, -0.11599932610988617, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>10.1029/2020JE006706\\nJewitt, D. 2003, Earth M...</td>\n",
       "      <td>[-0.06283451616764069, 0.021166836842894554, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences  \\\n",
       "0    Draft version August 14, 2023\\nTypeset using L...   \n",
       "1    2J. Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Fo...   \n",
       "2    We define a novel framework: firstly to predic...   \n",
       "3    We predict the spatial and compositional distr...   \n",
       "4    Selecting ISO water mass\\nfraction as an examp...   \n",
       "..                                                 ...   \n",
       "388  SDSS-IV is managed by the Astrophysical Resear...   \n",
       "389  University of Tokyo, the Korean Participation ...   \n",
       "390              Software: NumPy (Harris et al. 2020);   \n",
       "391  SciPy (Virtanen et al. 2020); Astropy (Astropy...   \n",
       "392  10.1029/2020JE006706\\nJewitt, D. 2003, Earth M...   \n",
       "\n",
       "                                               vectors  \n",
       "0    [-0.0655135065317154, -0.09104187041521072, 0....  \n",
       "1    [-0.07847049832344055, -0.12151646614074707, 0...  \n",
       "2    [-0.07799108326435089, -0.08398671448230743, 0...  \n",
       "3    [-0.053385745733976364, -0.037147391587495804,...  \n",
       "4    [-0.06326977908611298, -0.01720457896590233, 0...  \n",
       "..                                                 ...  \n",
       "388  [-0.05012284219264984, -0.10081170499324799, -...  \n",
       "389  [-0.07460089027881622, -0.06173836067318916, 0...  \n",
       "390  [-0.07249360531568527, -0.05101025104522705, -...  \n",
       "391  [-0.14471648633480072, -0.11599932610988617, 0...  \n",
       "392  [-0.06283451616764069, 0.021166836842894554, 0...  \n",
       "\n",
       "[393 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddb725-e0e7-4c00-a22b-3234eacf6bd1",
   "metadata": {},
   "source": [
    "## 4. Searching with a Query using KDB.AI\n",
    "\n",
    "Now that the embeddings are stored in KDB.AI, we can perform semantic search using `search`. \n",
    "\n",
    "First, we embed our search term using the Sentence Transformer model as before. Then we search our index to return to 3 most similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8666561e-e9b2-4c9f-95f4-add789be416d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                           sentences  \\\n",
       " 0  2J. Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Fo...   \n",
       " 1  In this work, we develop\\nthis method and appl...   \n",
       " 2  Keywords: Interstellar objects (52), Small Sol...   \n",
       " \n",
       "                                              vectors  __nn_distance  \n",
       " 0  [-0.07847049832344055, -0.12151646614074707, 0...       0.640911  \n",
       " 1  [-0.08688259869813919, -0.023635469377040863, ...       0.668817  \n",
       " 2  [-0.08041016012430191, -0.035552043467760086, ...       0.678942  ]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"number of interstellar objects in the milky way\"\n",
    "search_term_vector = model.encode(search_term)\n",
    "search_term_list = [search_term_vector.tolist()]\n",
    "\n",
    "results = table.search(search_term_list, n=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91762de7",
   "metadata": {},
   "source": [
    "The results returned from `table.search` show the closest matches along with value of nearest neighbour distances `nn_distance`. Let's print the output so we can see the full sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0f5ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2J. Ted Mackereth\\n ,3, 4, 5, ∗and\\nJohn C. Forbes\\n2\\n1Department of Physics, University of Oxford, Denys Wilkinson Building, Keble Road, Oxford, OX1 3RH, UK\\n2School of Physical and Chemical Sciences—Te Kura Mat¯ u, University of Canterbury, Private Bag 4800, Christchurch 8140, New Zealand\\n3Just Group plc, Enterprise House, Bancroft road, Reigate, Surrey RH2 7RP, UK\\n4Canadian Institute for Theoretical Astrophysics, University of Toronto, 60 St. George Street, Toronto, ON, M5S 3H8, Canada\\n5Dunlap Institute for Astronomy and Astrophysics, University of Toronto, 50 St. George Street, Toronto, ON M5S 3H4, Canada\\nABSTRACT\\nThe Milky Way is thought to host a huge population of interstellar objects (ISOs), numbering\\napproximately 1015pc−3around the Sun, which are formed and shaped by a diverse set of processes\\nranging from planet formation to galactic dynamics.\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    In this work, we develop\\nthis method and apply it to the stellar population of the Milky Way, estimated with data from the APOGEE survey, to\\npredict a broader set of properties of our own Galaxy’s population of interstellar objects.\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Keywords: Interstellar objects (52), Small Solar System bodies(1469), Galaxy Evolution (594)\\n1.INTRODUCTION\\n1I/‘Oumuamua (Meech et al. 2017) and 2I/Borisov1are the first two observed samples from a highly numerous\\npopulation: interstellar objects (ISOs).\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "results[0][\"sentences\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff8ba0",
   "metadata": {},
   "source": [
    "We can see these sentences do reference our search term 'number of interstellar objects in the milky way' in some way. Let's try another search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5f624af-a151-40e5-9a6f-9e7253f038fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                             The pop-\\nulation’s dominant dynamical formation mechanisms would preferentially harvest more distant, ice-rich planetesimals\\nfrom the disks of the source systems.\n",
       "1                                                                                                                                                                                                                                                                                                                                                             A protoplanetary disk has to first order the same composition as the star it forms around,\\nsince they both form from the same molecular cloud core.\n",
       "2    While in reality, stars will each produce a distribution of ISOs that\\nformed at different positions in their protoplanetary disk and thus have a range of compositions, this simplification\\nof only modelling planetesimals which form exterior to the water ice line is justified by the proportionally greater\\nreservoir of snowline-exterior planetesimals, and the higher efficiencies of formation mechanisms dynamically stripping\\nthem into the interstellar population (Fitzsimmons et al. 2023).\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"how does planet formation occur\"\n",
    "search_term_vector = model.encode(search_term)\n",
    "search_term_list = [search_term_vector.tolist()]\n",
    "\n",
    "results = table.search(search_term_list, n=3)\n",
    "results[0][\"sentences\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce337f",
   "metadata": {},
   "source": [
    "Again, we can see these sentences do reference our search term 'how does planet formation occur' in some way. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
